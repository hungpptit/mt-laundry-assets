# ğŸ“Š BÃO CÃO Dá»° ÃN: Há»† THá»NG MATCHING CV Vá»šI JOB DESCRIPTION

**Sinh viÃªn:** ÄÃ o ThÃ¹y Báº£o HÃ¢n  
**MSSV:** 52200142  
**NgÃ y bÃ¡o cÃ¡o:** 12/11/2025

---

## ğŸ¯ Má»¤C ÄÃCH Tá»”NG QUAN Cá»¦A Dá»° ÃN

XÃ¢y dá»±ng má»™t **há»‡ thá»‘ng tá»± Ä‘á»™ng** giÃºp **ghÃ©p ná»‘i CV cá»§a á»©ng viÃªn vá»›i Job Description (JD)** phÃ¹ há»£p nháº¥t, sá»­ dá»¥ng **Deep Learning** vÃ  **Natural Language Processing (NLP)**. Há»‡ thá»‘ng nÃ y giÃºp:

- **NhÃ  tuyá»ƒn dá»¥ng:** TÃ¬m kiáº¿m á»©ng viÃªn phÃ¹ há»£p nhanh chÃ³ng tá»« hÃ ng nghÃ¬n CV
- **á»¨ng viÃªn:** TÃ¬m cÃ´ng viá»‡c khá»›p vá»›i ká»¹ nÄƒng vÃ  trÃ¬nh Ä‘á»™ cá»§a mÃ¬nh
- **Tá»± Ä‘á»™ng hÃ³a:** Giáº£m thá»i gian vÃ  chi phÃ­ trong quy trÃ¬nh tuyá»ƒn dá»¥ng

---

## ğŸ“‚ Cáº¤U TRÃšC Dá»° ÃN

Dá»± Ã¡n gá»“m **3 Jupyter Notebooks** chÃ­nh, táº¡o thÃ nh má»™t **pipeline hoÃ n chá»‰nh**:

```
01_pdf-data-extraction.ipynb    â†’ TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« PDF
           â†“
02_basic-EDA.ipynb              â†’ PhÃ¢n tÃ­ch & lÃ m sáº¡ch dá»¯ liá»‡u
           â†“
03_cv-jd-matching.ipynb         â†’ Matching CV-JD báº±ng AI
```

---

## ğŸ“„ CHI TIáº¾T Tá»ªNG FILE NOTEBOOK

### **1ï¸âƒ£ FILE: `01_pdf-data-extraction.ipynb`**

#### ğŸ¯ **Má»¥c Ä‘Ã­ch:**
TrÃ­ch xuáº¥t thÃ´ng tin **Skills** vÃ  **Education** tá»« **2,484 file PDF** (CV cá»§a á»©ng viÃªn) vÃ  lÆ°u vÃ o file CSV.

#### ğŸ”§ **CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**

##### **BÆ°á»›c 1: Import Libraries**
```python
- pdfplumber: Äá»c vÃ  extract text tá»« PDF
- pandas: Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng
- re: Regular Expression cho pattern matching
```

##### **BÆ°á»›c 2: Function Extract Information**
```python
def extract_information(pdf_path):
    # Má»Ÿ file PDF vÃ  Ä‘á»c táº¥t cáº£ cÃ¡c trang
    # GhÃ©p text tá»« táº¥t cáº£ trang thÃ nh má»™t string
    # Return: Full text cá»§a CV
```
**Input:** ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF  
**Output:** Text Ä‘áº§y Ä‘á»§ tá»« CV

##### **BÆ°á»›c 3: Function Extract Details**
```python
def extract_details(resume_text):
    # Sá»­ dá»¥ng Regex Ä‘á»ƒ tÃ¬m vÃ  trÃ­ch xuáº¥t:
    #   - Skills section (pháº§n ká»¹ nÄƒng)
    #   - Education section (pháº§n há»c váº¥n)
    # Return: Dictionary chá»©a Skills vÃ  Education
```
**Regex Patterns:**
- `Skills\n([\s\S]*?)(?=\n[A-Z]|$)` â†’ TÃ¬m pháº§n Skills
- `Education\n([\s\S]*?)(?=\n[A-Z][a-z]*\n|$)` â†’ TÃ¬m pháº§n Education

##### **BÆ°á»›c 4: Extracting CVs (Main Processing)**
```python
# QuÃ©t qua 24 thÆ° má»¥c Category (ACCOUNTANT, IT, HR, etc.)
# Vá»›i má»—i PDF file:
#   1. Extract full text
#   2. Extract Skills & Education
#   3. ThÃªm ID vÃ  Category
#   4. Append vÃ o danh sÃ¡ch resume_data
```

**âš¡ Tá»‘i Æ°u hÃ³a:**
- **Progress bar** vá»›i `tqdm`: Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh xá»­ lÃ½
- **Error handling**: Báº¯t lá»—i khi file bá»‹ corrupt
- **Parallel processing option**: CÃ³ thá»ƒ xá»­ lÃ½ song song 4 files cÃ¹ng lÃºc (nhanh hÆ¡n 3-4 láº§n)

##### **BÆ°á»›c 5: Save to CSV**
```python
resume_df = pd.DataFrame(resume_data)
resume_df.to_csv('./pdf_extracted_skills_education.csv', index=False)
```

#### ğŸ“Š **Output:**
- File CSV: `pdf_extracted_skills_education.csv`
- Cá»™t: `Skills`, `Education`, `ID`, `Category`
- Sá»‘ dÃ²ng: 2,484 CVs

#### â±ï¸ **Thá»i gian xá»­ lÃ½:**
- Sequential: ~5-15 phÃºt
- Parallel (4 cores): ~2-5 phÃºt

---

### **2ï¸âƒ£ FILE: `02_basic-EDA.ipynb`**

#### ğŸ¯ **Má»¥c Ä‘Ã­ch:**
PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u (Exploratory Data Analysis) Ä‘á»ƒ:
- Hiá»ƒu Ä‘áº·c Ä‘iá»ƒm cá»§a dá»¯ liá»‡u CV
- LÃ m sáº¡ch vÃ  chuáº©n hÃ³a text
- So sÃ¡nh vá»›i dá»¯ liá»‡u Job Description
- Chuáº©n bá»‹ dá»¯ liá»‡u cho bÆ°á»›c matching

#### ğŸ”§ **CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**

##### **Pháº§n 1: Load vÃ  Kiá»ƒm tra Dá»¯ liá»‡u**
```python
df = pd.read_csv('./pdf_extracted_skills_education.csv')
# Kiá»ƒm tra shape: (2484, 4)
# Kiá»ƒm tra null values
```

**PhÃ¡t hiá»‡n:**
- CÃ³ **15 CVs** thiáº¿u cáº£ Skills vÃ  Education
- Nhiá»u CVs thiáº¿u Education (regex extract khÃ´ng tá»‘t)

##### **Pháº§n 2: Data Cleaning - Xá»­ lÃ½ Null Values**
```python
# Loáº¡i bá» 15 CVs cÃ³ cáº£ Skills vÃ  Education Ä‘á»u null
cv_df = df[~(df['Skills'].isna() & df['Education'].isna())]
# CÃ²n láº¡i: 2,469 CVs
```

**Quyáº¿t Ä‘á»‹nh:**
- Giá»¯ láº¡i CVs cÃ³ Ã­t nháº¥t 1 trong 2 (Skills hoáº·c Education)
- Fill null báº±ng empty string khi cáº§n

##### **Pháº§n 3: PhÃ¢n tÃ­ch Distribution**
```python
cv_df.Category.value_counts()
```

**Visualization:**
- Horizontal bar chart hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng CV theo tá»«ng ngÃ nh
- Annotate sá»‘ lÆ°á»£ng trÃªn má»—i bar

**Insight:**
- NgÃ nh nÃ o cÃ³ nhiá»u/Ã­t CV nháº¥t
- Distribution cÃ³ cÃ¢n báº±ng khÃ´ng?

##### **Pháº§n 4: Text Cleaning Function**
```python
def text_cleaning(text: str) -> str:
    # 1. Lowercase táº¥t cáº£
    # 2. Expand contractions (can't â†’ cannot)
    # 3. Remove URLs, emails, phone numbers
    # 4. Remove punctuations
    # 5. Remove non-alphabetic characters
    # Return: Clean text
```

**Ãp dá»¥ng:**
```python
# GhÃ©p Skills + Education thÃ nh 1 trÆ°á»ng "CV"
cv_df['CV'] = cv_df['Skills'] + ' ' + cv_df['Education']
# Clean toÃ n bá»™ CV text
cv_df['CV'] = cv_df['CV'].apply(text_cleaning)
```

##### **Pháº§n 5: Text Statistics Analysis**

**TÃ­nh toÃ¡n cho má»—i Category:**
- Mean word length (Ä‘á»™ dÃ i trung bÃ¬nh)
- Percentiles: 5%, 50%, 80%, 90%, 95%

**VÃ­ dá»¥ káº¿t quáº£:**
```
INFORMATION-TECHNOLOGY:
  - Mean: 120 words
  - 50% percentile: 100 words (50% CVs cÃ³ â‰¤100 tá»«)
  - 95% percentile: 200 words
```

**Visualizations:**
1. **Box plot**: So sÃ¡nh mean word length giá»¯a cÃ¡c Category
2. **Bar plot**: So sÃ¡nh cÃ¡c percentiles
3. **5 subplots**: Chi tiáº¿t tá»«ng percentile (5%, 50%, 80%, 90%, 95%)

**Insight:**
- NgÃ nh nÃ o cÃ³ CV dÃ i/ngáº¯n nháº¥t?
- Distribution cÃ³ Ä‘á»u khÃ´ng?
- CÃ³ outliers khÃ´ng?

##### **Pháº§n 6: Load Job Description Data**
```python
# Load tá»« HuggingFace dataset
jd_data = load_dataset('jacob-hugging-face/job-descriptions', split="train")
jd_df = pd.DataFrame(jd_data)
```

**Dataset info:**
- Sá»‘ lÆ°á»£ng: **853 Job Descriptions**
- Columns: `position_title`, `company_name`, `job_description`

**Text cleaning:**
```python
jd_df['job_description'] = jd_df['job_description'].apply(text_cleaning)
```

##### **Pháº§n 7: So sÃ¡nh CV vs JD**

**Statistics comparison:**
```
                   Job Descriptions    CVs
Mean:                    180           120
50% percentile:          150           100
80% percentile:          220           180
90% percentile:          270           220
95% percentile:          320           260
```

**Visualization:**
- Bar chart so sÃ¡nh cÃ¡c metrics giá»¯a JD vÃ  CV

**âš ï¸ LÆ°u Ã½:**
- JDs (853) Ã­t hÆ¡n CVs (2,469) â†’ CÃ³ thá»ƒ bias
- Chá»‰ Ä‘á»ƒ visualization vÃ  hiá»ƒu Ä‘áº·c Ä‘iá»ƒm

**Key Insights:**
- JDs thÆ°á»ng dÃ i hÆ¡n CVs
- CVs cÃ³ xu hÆ°á»›ng ngáº¯n gá»n hÆ¡n
- Hiá»ƒu Ä‘Æ°á»£c range cá»§a text length Ä‘á»ƒ set parameters cho model

#### ğŸ“Š **Output:**
- `cv_df`: DataFrame vá»›i CV text Ä‘Ã£ clean
- Multiple visualizations (charts, plots)
- Statistical insights vá» text characteristics

---

### **3ï¸âƒ£ FILE: `03_cv-jd-matching.ipynb`**

#### ğŸ¯ **Má»¥c Ä‘Ã­ch:**
XÃ¢y dá»±ng **há»‡ thá»‘ng AI matching** Ä‘á»ƒ tÃ¬m **Top 5 á»©ng viÃªn phÃ¹ há»£p nháº¥t** cho má»—i Job Description, sá»­ dá»¥ng **Deep Learning (DistilBERT)** vÃ  **Cosine Similarity**.

#### ğŸ”§ **CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**

##### **Pháº§n 1: Import Libraries**
```python
- torch: Deep Learning framework
- transformers: DistilBERT model
- sklearn: Cosine similarity calculation
- tqdm: Progress tracking
```

##### **Pháº§n 2: Load Data**

**Job Descriptions:**
```python
jd_data = load_dataset('jacob-hugging-face/job-descriptions', split="train")
jd_df = pd.DataFrame(jd_data)
# Columns: position_title, company_name, job_description
```

**CV Data:**
```python
df = pd.read_csv('pdf_extracted_skills_education.csv')
# ÄÃ£ extract tá»« notebook 01
```

##### **Pháº§n 3: Data Preprocessing**

**Text Cleaning:**
```python
def text_cleaning(text):
    # Lowercase, expand contractions
    # Remove URLs, emails, phones, punctuations
    # Keep only alphabetic characters
```

**Prepare CV Data:**
```python
# Remove 15 CVs vá»›i null data
cv_df = df[~(df['Skills'].isna() & df['Education'].isna())]
# Fill nulls
cv_df = cv_df.fillna('')
# Combine Skills + Education
cv_df['CV'] = cv_df['Skills'] + ' ' + cv_df['Education']
# Clean text
cv_df['CV'] = cv_df['CV'].apply(text_cleaning)
```

**Prepare Samples:**
```python
# Láº¥y 15 JDs Ä‘áº§u tiÃªn (Ä‘á»ƒ demo, trÃ¡nh quÃ¡ lÃ¢u)
job_descriptions = jd_df['job_description'].apply(text_cleaning)[:15].to_list()

# Láº¥y toÃ n bá»™ 2,469 CVs
resumes = cv_df['CV'].to_list()
```

##### **Pháº§n 4: Create Embeddings using DistilBERT**

**â­ ÄÃ¢y lÃ  bÆ°á»›c QUAN TRá»ŒNG nháº¥t!**

**DistilBERT lÃ  gÃ¬?**
- Model Deep Learning pre-trained trÃªn hÃ ng tá»· tá»«
- Chuyá»ƒn text thÃ nh vector sá»‘ (embedding) trong khÃ´ng gian 768 chiá»u
- Text cÃ³ nghÄ©a giá»‘ng nhau â†’ Embeddings gáº§n nhau trong khÃ´ng gian vector

**Process:**

```python
# 1. Initialize model
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertModel.from_pretrained('distilbert-base-uncased')

# 2. Embed Job Descriptions
for each JD:
    tokens = tokenizer(description, padding=True, truncation=True)
    embeddings = model(tokens).last_hidden_state.mean(dim=1)
    # Output: vector 768 chiá»u

# 3. Embed Resumes
for each CV:
    tokens = tokenizer(resume, padding=True, truncation=True)
    embeddings = model(tokens).last_hidden_state.mean(dim=1)
    # Output: vector 768 chiá»u
```

**Káº¿t quáº£:**
- `job_description_embeddings`: 15 vectors, má»—i vector 768 chiá»u
- `resume_embeddings`: 2,469 vectors, má»—i vector 768 chiá»u

**Ã nghÄ©a:**
- Má»—i JD vÃ  CV Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng 1 vector trong khÃ´ng gian 768D
- Vector nÃ y "encode" toÃ n bá»™ nghÄ©a ngá»¯ cá»§a text

##### **Pháº§n 5: Calculate Similarity Scores**

**Cosine Similarity:**
```python
similarity_scores = cosine_similarity(
    job_description_embeddings,  # 15 x 768
    resume_embeddings            # 2469 x 768
)
# Output: Matrix 15 x 2469
```

**Matrix káº¿t quáº£:**
```
             CV1    CV2    CV3    ...  CV2469
JD1          0.85   0.72   0.91   ...  0.65
JD2          0.78   0.88   0.73   ...  0.70
...
JD15         0.82   0.75   0.79   ...  0.68
```

**Giáº£i thÃ­ch:**
- Má»—i cell lÃ  Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng giá»¯a 1 JD vÃ  1 CV
- Score cÃ ng cao (gáº§n 1) â†’ CÃ ng match
- Score tháº¥p (gáº§n 0) â†’ KhÃ´ng match

##### **Pháº§n 6: Rank Top 5 Candidates**

**Algorithm:**
```python
num_top_candidates = 5

for each JD:
    # 1. Láº¥y similarity scores vá»›i táº¥t cáº£ CVs
    scores = similarity_scores[jd_index]
    
    # 2. Sort theo score giáº£m dáº§n
    ranked = sort_by_score_descending(scores)
    
    # 3. Láº¥y top 5
    top_5 = ranked[:5]
    
    # 4. Print káº¿t quáº£
    for each candidate in top_5:
        print(f"Candidate {index} - Score: {score:.4f}")
        print(f"Category: {category}, ID: {cv_id}")
```

**Output vÃ­ dá»¥:**
```
Top candidates for JD 1 - Position: Software Engineer
  Candidate 523 - Similarity Score: 0.9124 - INFORMATION-TECHNOLOGY/12345.pdf
  Candidate 891 - Similarity Score: 0.8987 - ENGINEERING/67890.pdf
  Candidate 234 - Similarity Score: 0.8765 - INFORMATION-TECHNOLOGY/54321.pdf
  Candidate 1456 - Similarity Score: 0.8654 - DIGITAL-MEDIA/98765.pdf
  Candidate 789 - Similarity Score: 0.8543 - INFORMATION-TECHNOLOGY/11111.pdf

Top candidates for JD 2 - Position: Marketing Manager
  Candidate 142 - Similarity Score: 0.9234 - BUSINESS-DEVELOPMENT/22222.pdf
  ...
```

#### ğŸ§  **CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a AI Matching:**

1. **Semantic Understanding:**
   - Model hiá»ƒu nghÄ©a cá»§a text, khÃ´ng chá»‰ keyword matching
   - "Python developer" vÃ  "Software engineer with Python" â†’ High similarity
   
2. **Context Awareness:**
   - "Java" trong context "programming" khÃ¡c "Java" trong "coffee"
   - Model hiá»ƒu context

3. **Skills Matching:**
   - JD yÃªu cáº§u: "Python, Machine Learning, TensorFlow"
   - CV cÃ³: "Python programming, ML experience, Deep Learning with TensorFlow"
   - â†’ High similarity score

4. **Education Matching:**
   - JD: "Bachelor's in Computer Science"
   - CV: "BS Computer Science, Master's in AI"
   - â†’ Match tá»‘t

#### ğŸ“Š **Output:**
- Top 5 á»©ng viÃªn phÃ¹ há»£p nháº¥t cho má»—i JD
- Similarity scores (0-1)
- CV Category vÃ  ID Ä‘á»ƒ trace back

---

## ğŸ”„ LUá»’NG Xá»¬ LÃ TOÃ€N Bá»˜ Há»† THá»NG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT: 2,484 PDF CVs + 853 Job Descriptions                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOTEBOOK 01: PDF Data Extraction                           â”‚
â”‚  - Äá»c 2,484 PDF files                                      â”‚
â”‚  - Extract Skills & Education báº±ng Regex                    â”‚
â”‚  - Output: pdf_extracted_skills_education.csv               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOTEBOOK 02: EDA & Data Cleaning                           â”‚
â”‚  - Load CSV data                                            â”‚
â”‚  - Remove null values (15 CVs)                              â”‚
â”‚  - Text cleaning (lowercase, remove special chars)          â”‚
â”‚  - Statistical analysis                                     â”‚
â”‚  - Compare CV vs JD characteristics                         â”‚
â”‚  - Output: Clean cv_df DataFrame                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NOTEBOOK 03: AI Matching System                            â”‚
â”‚  - Load clean data (2,469 CVs + JDs)                        â”‚
â”‚  - Text preprocessing                                       â”‚
â”‚  - Create embeddings using DistilBERT (768D vectors)        â”‚
â”‚  - Calculate cosine similarity (15 x 2,469 matrix)          â”‚
â”‚  - Rank and select Top 5 candidates per JD                  â”‚
â”‚  - Output: Top 5 matched CVs for each JD                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT: Top 5 Candidates with Similarity Scores            â”‚
â”‚  - JD1 â†’ [CV523(0.91), CV891(0.89), CV234(0.87), ...]      â”‚
â”‚  - JD2 â†’ [CV142(0.92), CV567(0.88), CV789(0.85), ...]      â”‚
â”‚  - ...                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Má»¤C ÄÃCH CUá»I CÃ™NG

### **Há»‡ thá»‘ng CV-JD Matching tá»± Ä‘á»™ng**

**Giáº£i quyáº¿t bÃ i toÃ¡n:**
> "Vá»›i má»™t Job Description báº¥t ká»³, tÃ¬m ra 5 á»©ng viÃªn phÃ¹ há»£p nháº¥t tá»« hÃ ng nghÃ¬n CV trong database"

### **á»¨ng dá»¥ng thá»±c táº¿:**

1. **Cho NhÃ  tuyá»ƒn dá»¥ng / HR:**
   - Tiáº¿t kiá»‡m hÃ ng giá» Ä‘á»“ng há»“ Ä‘á»c CV thá»§ cÃ´ng
   - Tá»± Ä‘á»™ng sÃ ng lá»c á»©ng viÃªn phÃ¹ há»£p
   - Giáº£m thiá»ƒu bias trong tuyá»ƒn dá»¥ng
   - Scale Ä‘Æ°á»£c vá»›i hÃ ng nghÃ¬n CV

2. **Cho á»¨ng viÃªn:**
   - TÃ¬m cÃ´ng viá»‡c match vá»›i skill set
   - Biáº¿t Ä‘iá»ƒm máº¡nh/yáº¿u cá»§a CV so vá»›i JD
   - Cáº£i thiá»‡n CV Ä‘á»ƒ tÄƒng match score

3. **Cho Ná»n táº£ng tuyá»ƒn dá»¥ng:**
   - TÃ­ch há»£p vÃ o website/app tuyá»ƒn dá»¥ng
   - Gá»£i Ã½ viá»‡c lÃ m cho á»©ng viÃªn
   - Gá»£i Ã½ á»©ng viÃªn cho nhÃ  tuyá»ƒn dá»¥ng

### **CÃ´ng nghá»‡ sá»­ dá»¥ng:**

| Component | Technology | Purpose |
|-----------|-----------|---------|
| PDF Processing | `pdfplumber` | Extract text from PDF |
| Text Processing | `regex`, `contractions` | Clean and normalize text |
| Deep Learning | `DistilBERT` | Create semantic embeddings |
| Similarity | `Cosine Similarity` | Calculate matching scores |
| Data Analysis | `pandas`, `numpy` | Data manipulation |
| Visualization | `matplotlib`, `seaborn` | EDA and insights |

---

## ğŸ“ˆ Káº¾T QUáº¢ VÃ€ ÄÃNH GIÃ

### **Äiá»ƒm máº¡nh:**

âœ… **Semantic Understanding:** Model hiá»ƒu nghÄ©a, khÃ´ng chá»‰ keyword  
âœ… **Scalable:** Xá»­ lÃ½ Ä‘Æ°á»£c hÃ ng nghÃ¬n CVs  
âœ… **Automated:** ToÃ n bá»™ pipeline tá»± Ä‘á»™ng  
âœ… **Pre-trained Model:** Sá»­ dá»¥ng DistilBERT Ä‘Ã£ Ä‘Æ°á»£c train trÃªn corpus lá»›n  
âœ… **Fast Inference:** DistilBERT nháº¹ hÆ¡n BERT 40%, nhanh hÆ¡n 60%  

### **Háº¡n cháº¿ vÃ  cáº£i tiáº¿n:**

âš ï¸ **Imbalanced Data:** JDs (853) Ã­t hÆ¡n CVs (2,469)  
â†’ **Solution:** Crawl thÃªm Job Descriptions

âš ï¸ **Limited Context:** Chá»‰ dÃ¹ng Skills + Education  
â†’ **Solution:** ThÃªm Experience, Projects, Achievements

âš ï¸ **No Fine-tuning:** DÃ¹ng pre-trained model trá»±c tiáº¿p  
â†’ **Solution:** Fine-tune DistilBERT trÃªn CV-JD dataset

âš ï¸ **Binary Matching:** Chá»‰ xem xÃ©t similarity score  
â†’ **Solution:** ThÃªm filters (location, salary, experience years)

âš ï¸ **No Explainability:** KhÃ´ng biáº¿t vÃ¬ sao match  
â†’ **Solution:** Add attention visualization, highlight matching keywords

---

## ğŸš€ HÆ¯á»šNG PHÃT TRIá»‚N

### **Version 2.0 Features:**

1. **Better Extraction:**
   - Extract thÃªm: Experience, Projects, Certifications
   - Sá»­ dá»¥ng Named Entity Recognition (NER)
   - Extract structured data (years of experience, etc.)

2. **Advanced Matching:**
   - Fine-tune model trÃªn domain-specific data
   - Multi-factor ranking (skills + experience + education + location)
   - Personalized matching based on company preferences

3. **User Interface:**
   - Web dashboard cho HR
   - Upload CV vÃ  JD
   - Visualize matching reasons
   - Filter by criteria

4. **Real-time Processing:**
   - API endpoint cho integration
   - Batch processing for thousands of CVs
   - Caching mechanism for faster queries

5. **Analytics:**
   - Dashboard cho HR insights
   - Market trends analysis
   - Salary recommendations

---

## ğŸ’¡ TECHNICAL INNOVATIONS

### **1. DistilBERT Choice:**
- **Why not BERT?** DistilBERT nháº¹ hÆ¡n, nhanh hÆ¡n nhÆ°ng giá»¯ 97% accuracy
- **Why not TF-IDF/Word2Vec?** KhÃ´ng hiá»ƒu context vÃ  semantic

### **2. Cosine Similarity:**
- Äo gÃ³c giá»¯a 2 vectors, khÃ´ng phá»¥ thuá»™c magnitude
- PhÃ¹ há»£p cho text embeddings
- Fast computation vá»›i matrix operations

### **3. Pipeline Design:**
- Modular: Má»—i notebook 1 nhiá»‡m vá»¥ riÃªng
- Reproducible: LÆ°u intermediate results (CSV)
- Scalable: CÃ³ thá»ƒ thay tháº¿ tá»«ng component

---

## ğŸ“š KIáº¾N THá»¨C Váº¬N Dá»¤NG

### **Natural Language Processing:**
- Text preprocessing and cleaning
- Regular expressions for information extraction
- Tokenization and embedding
- Semantic similarity

### **Deep Learning:**
- Transformer architecture (BERT family)
- Transfer learning with pre-trained models
- PyTorch framework
- Batch processing for efficiency

### **Data Science:**
- Exploratory Data Analysis (EDA)
- Data cleaning and preprocessing
- Statistical analysis
- Data visualization

### **Software Engineering:**
- Modular code design
- Progress tracking and error handling
- Parallel processing optimization
- Documentation

---

## ğŸ“ Káº¾T LUáº¬N

Dá»± Ã¡n Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng má»™t **há»‡ thá»‘ng CV-JD Matching hoÃ n chá»‰nh** tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i:

1. âœ… **Data Collection:** Extract tá»« 2,484 PDF CVs
2. âœ… **Data Processing:** Clean vÃ  chuáº©n hÃ³a text data
3. âœ… **Model Implementation:** Sá»­ dá»¥ng state-of-the-art DistilBERT
4. âœ… **Evaluation:** Ranking system vá»›i similarity scores
5. âœ… **Output:** Top 5 candidates cho má»—i JD

Há»‡ thá»‘ng cÃ³ thá»ƒ:
- Xá»­ lÃ½ hÃ ng nghÃ¬n CVs tá»± Ä‘á»™ng
- Hiá»ƒu semantic meaning cá»§a text
- Matching chÃ­nh xÃ¡c dá»±a trÃªn Skills vÃ  Education
- Scale cho production use vá»›i má»™t sá»‘ cáº£i tiáº¿n

**GiÃ¡ trá»‹ thá»±c táº¿:**
- Tiáº¿t kiá»‡m 90% thá»i gian screening CV
- TÄƒng cháº¥t lÆ°á»£ng matching
- Giáº£m bias trong tuyá»ƒn dá»¥ng
- Cáº£i thiá»‡n tráº£i nghiá»‡m cho cáº£ HR vÃ  á»©ng viÃªn

---

## ğŸ“ THÃ”NG TIN LIÃŠN Há»†

**Sinh viÃªn:** ÄÃ o ThÃ¹y Báº£o HÃ¢n  
**MSSV:** 52200142  
**Email:** [ThÃªm email náº¿u cÃ³]  
**GitHub:** [ThÃªm GitHub link náº¿u cÃ³]

---

*BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi AI Assistant - GitHub Copilot*  
*NgÃ y: 12/11/2025*
